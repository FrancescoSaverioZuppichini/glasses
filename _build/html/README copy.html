

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Glasses üòé &mdash; Glasses  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Glasses
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Notes/tutorials/Interpretability.html">Interpretability</a></li>
<li class="toctree-l1"><a class="reference internal" href="Notes/tutorials/Segmentation.html">Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Notes/tutorials/Transfer%20Learning.html">Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Notes/tutorials/installation.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">glasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="glasses.nn.html">glasses.nn package</a></li>
<li class="toctree-l1"><a class="reference internal" href="glasses.models.html">glasses.models package</a></li>
<li class="toctree-l1"><a class="reference internal" href="glasses.utils.html">glasses.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="glasses.data.html">glasses.data package</a></li>
<li class="toctree-l1"><a class="reference internal" href="glasses.interpretability.html">glasses.interpretability package</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Glasses</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Glasses üòé</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/README copy.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>
</pre></div>
</div>
<div class="section" id="glasses">
<h1>Glasses üòé<a class="headerlink" href="#glasses" title="Permalink to this headline">¬∂</a></h1>
<p><img alt="alt" src="https://github.com/FrancescoSaverioZuppichini/glasses/blob/develop/docs/_static/images/background.png?raw=true" /></p>
<p><a class="reference external" href="https://codecov.io/gh/FrancescoSaverioZuppichini/glasses"><img alt="codecov" src="https://codecov.io/gh/FrancescoSaverioZuppichini/glasses/branch/develop/graph/badge.svg" /></a></p>
<p>Compact, concise and customizable
deep learning computer vision library</p>
<p><strong>Models have been stored into the <a class="reference external" href="https://huggingface.co/glasses">hugging face hub!</a></strong></p>
<p>Doc is <a class="reference external" href="https://francescosaveriozuppichini.github.io/glasses/index.html">here</a></p>
<div class="section" id="tl-tr">
<h2>TL;TR<a class="headerlink" href="#tl-tr" title="Permalink to this headline">¬∂</a></h2>
<p>This library has</p>
<ul class="simple">
<li><p>human readable code, no <em>research code</em></p></li>
<li><p>common component are shared across <a class="reference external" href="#Models">models</a></p></li>
<li><p><a class="reference external" href="#classification">same APIs</a> for all models (you learn them once and they are always the same)</p></li>
<li><p>clear and easy to use model constomization (see <a class="reference external" href="#block">here</a>)</p></li>
<li><p><a class="reference external" href="#classification">classification</a> and <a class="reference external" href="#segmentation">segmentation</a></p></li>
<li><p>emoji in the name ;)</p></li>
</ul>
<p>Stuff implemented so far:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/2010.11929.pdf">Training data-efficient image transformers &amp; distillation through attention</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/2010.11929.pdf">Vision Transformer -  An Image Is Worth 16x16 Words: Transformers For Image Recognition At Scale</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2004.08955">ResNeSt: Split-Attention Networks</a></p></li>
<li><p><a class="reference external" href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">AlexNet-  ImageNet Classification with Deep Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1608.06993">DenseNet - Densely Connected Convolutional Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1905.11946">EfficientNet - EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://blog.tensorflow.org/2020/03/higher-accuracy-on-vision-models-with-efficientnet-lite.html">EfficientNetLite - Higher accuracy on vision models with EfficientNet-Lite</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1901.03495">FishNet - FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction
</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1801.04381.pdf">MobileNet - MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2003.13678">RegNet - Designing Network Design Spaces</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1512.03385">ResNet - Deep Residual Learning for Image Recognition</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1812.01187.pdf">ResNetD - Bag of Tricks for Image Classification with Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1611.05431.pdf">ResNetXt - Aggregated Residual Transformations for Deep Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.02579">SEResNet - Concurrent Spatial and Channel Squeeze &amp; Excitation in Fully Convolutional Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1409.1556.pdf">VGG - Very Deep Convolutional Networks For Large-scale Image Recognition</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1605.07146.pdf">WideResNet - Wide Residual Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1612.03144">FPN - Feature Pyramid Networks for Object Detection</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1901.02446.pdf">PFPN - Panoptic Feature Pyramid Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1505.04597">UNet - U-Net: Convolutional Networks for Biomedical Image Segmentation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.02579">Squeeze and Excitation - Concurrent Spatial and Channel Squeeze &amp; Excitation in Fully Convolutional Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1910.03151.pdf">ECA - ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1810.12890">DropBlock: A regularization method for convolutional networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1406.4729.pdf">Spatial Pyramid Pooling in Deep Convolutional Networks  for Visual Recognition</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1910.01279">Score-CAM: Score-Weighted Visual Explanations for Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a></p></li>
</ul>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¬∂</a></h2>
<p>You can install <code class="docutils literal notranslate"><span class="pre">glasses</span></code> using pip by running</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">FrancescoSaverioZuppichini</span><span class="o">/</span><span class="n">glasses</span>
</pre></div>
</div>
<div class="section" id="motivations">
<h3>Motivations<a class="headerlink" href="#motivations" title="Permalink to this headline">¬∂</a></h3>
<p>Almost all existing implementations of the most famous model are written with very bad coding practices, what today is called <em>research code</em>. I struggled myself to understand some of the implementations that in the end were just a few lines of code.</p>
<p>Most of them are missing a global structure, they used tons of code repetition, they are not easily customizable and not tested. Since I do computer vision for living, so I needed a way to make my life easier.</p>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¬∂</a></h2>
<p>The API are shared across <strong>all</strong> models!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">glasses.models</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoTransform</span>
<span class="c1"># load one model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;resnet18&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">AutoTransform</span><span class="o">.</span><span class="n">from_name</span><span class="p">(</span><span class="s1">&#39;resnet18&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span> <span class="p">)</span> <span class="c1"># thanks to torchinfo</span>
<span class="n">AutoModel</span><span class="o">.</span><span class="n">models_table</span><span class="p">()</span> 
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>            Models                 
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ Name                   ‚îÉ Pretrained ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ resnet18               ‚îÇ true       ‚îÇ
‚îÇ resnet26               ‚îÇ true       ‚îÇ
‚îÇ resnet26d              ‚îÇ true       ‚îÇ
‚îÇ resnet34               ‚îÇ true       ‚îÇ
‚îÇ resnet34d              ‚îÇ true       ‚îÇ
‚îÇ resnet50               ‚îÇ true       ‚îÇ
...
</pre></div>
</div>
<div class="section" id="interpretability">
<h3>Interpretability<a class="headerlink" href="#interpretability" title="Permalink to this headline">¬∂</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">from</span> <span class="nn">glasses.interpretability</span> <span class="kn">import</span> <span class="n">GradCam</span><span class="p">,</span> <span class="n">SaliencyMap</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">Normalize</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://i.insider.com/5df126b679d7570ad2044f3e?width=700&amp;format=jpeg&amp;auto=webp&#39;</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">))</span>
<span class="c1"># un normalize when done</span>
<span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">transforms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">transforms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">std</span>
<span class="n">postprocessing</span> <span class="o">=</span> <span class="n">Normalize</span><span class="p">(</span><span class="o">-</span><span class="n">mean</span> <span class="o">/</span> <span class="n">std</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">std</span><span class="p">))</span>
<span class="c1"># apply preprocessing</span>
<span class="n">x</span> <span class="o">=</span>  <span class="n">tr</span><span class="p">(</span><span class="n">im</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">interpret</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">using</span><span class="o">=</span><span class="n">GradCam</span><span class="p">(),</span> <span class="n">postprocessing</span><span class="o">=</span><span class="n">postprocessing</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="alt" src="https://github.com/FrancescoSaverioZuppichini/glasses/blob/develop/docs/_static/images/grad_cam.png?raw=true" /></p>
</div>
</div>
<div class="section" id="classification">
<h2>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¬∂</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models</span> <span class="kn">import</span> <span class="n">ResNet</span>
<span class="c1"># change activation</span>
<span class="n">ResNet</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">)</span>
<span class="c1"># change number of classes</span>
<span class="n">ResNet</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="c1"># freeze only the convolution weights</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="n">who</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
<span class="c1"># get the last layer, usuful to hook to it if you want to get the embeeded vector</span>
<span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># what about resnet with inverted residuals?</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.efficientnet</span> <span class="kn">import</span> <span class="n">InvertedResidualBlock</span>
<span class="n">ResNet</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">block</span> <span class="o">=</span> <span class="n">InvertedResidualBlock</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="segmentation">
<h2>Segmentation<a class="headerlink" href="#segmentation" title="Permalink to this headline">¬∂</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">glasses.models.segmentation.unet</span> <span class="kn">import</span> <span class="n">UNet</span><span class="p">,</span> <span class="n">UNetDecoder</span>
<span class="c1"># vanilla Unet</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">UNet</span><span class="p">()</span>
<span class="c1"># let&#39;s change the encoder</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">UNet</span><span class="o">.</span><span class="n">from_encoder</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">AutoModel</span><span class="o">.</span><span class="n">from_name</span><span class="p">,</span> <span class="s1">&#39;efficientnet_b1&#39;</span><span class="p">))</span>
<span class="c1"># mmm I want more layers in the decoder!</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">UNet</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">UNetDecoder</span><span class="p">,</span> <span class="n">widths</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">]))</span>
<span class="c1"># maybe resnet was better</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">UNet</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="k">lambda</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">ResNet</span><span class="o">.</span><span class="n">resnet26</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
<span class="c1"># same API</span>
<span class="n">unet</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">))</span>
</pre></div>
</div>
<div class="section" id="more-examples">
<h3>More examples<a class="headerlink" href="#more-examples" title="Permalink to this headline">¬∂</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># change the decoder part</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">my_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">widths</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">512</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">my_head</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">))</span>
<span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="c1">#torch.Size([1, 1000])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="pretrained-models">
<h2>Pretrained Models<a class="headerlink" href="#pretrained-models" title="Permalink to this headline">¬∂</a></h2>
<p><strong>I am currently working on the pretrained models and the best way to make them available</strong></p>
<p>This is a list of all the pretrained models available so far!. They are all trained on <em>ImageNet</em>.</p>
<p>I used a <code class="docutils literal notranslate"><span class="pre">batch_size=64</span></code> and a GTX 1080ti to evaluale the models.</p>
<p>|                        |    top1 |    top5 |     time |   batch_size |
|:‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì|‚Äî‚Äî‚Äì:|‚Äî‚Äî‚Äì:|‚Äî‚Äî‚Äî:|‚Äî‚Äî‚Äî‚Äî-:|
| efficientnet_b3        | 0.82034 | 0.9603  | 199.599  |           64 |
| regnety_032            | 0.81958 | 0.95964 | 136.518  |           64 |
| deit_small_patch16_224 | 0.81082 | 0.95316 | 132.868  |           64 |
| resnet50d              | 0.80492 | 0.95128 |  97.5827 |           64 |
| cse_resnet50           | 0.80292 | 0.95048 | 108.765  |           64 |
| efficientnet_b2        | 0.80126 | 0.95124 | 127.177  |           64 |
| resnext101_32x8d       | 0.7921  | 0.94556 | 290.38   |           64 |
| wide_resnet101_2       | 0.7891  | 0.94344 | 277.755  |           64 |
| wide_resnet50_2        | 0.78464 | 0.94064 | 201.634  |           64 |
| efficientnet_b1        | 0.7831  | 0.94096 |  98.7143 |           64 |
| resnet152              | 0.7825  | 0.93982 | 186.191  |           64 |
| regnetx_032            | 0.7792  | 0.93996 | 319.558  |           64 |
| resnext50_32x4d        | 0.77628 | 0.9368  | 114.325  |           64 |
| regnety_016            | 0.77604 | 0.93702 |  96.547  |           64 |
| efficientnet_b0        | 0.77332 | 0.93566 |  67.2147 |           64 |
| resnet101              | 0.77314 | 0.93556 | 134.148  |           64 |
| densenet161            | 0.77146 | 0.93602 | 239.388  |           64 |
| resnet34d              | 0.77118 | 0.93418 |  59.9938 |           64 |
| densenet201            | 0.76932 | 0.9339  | 158.514  |           64 |
| regnetx_016            | 0.76684 | 0.9328  |  91.7536 |           64 |
| resnet26d              | 0.766   | 0.93188 |  70.6453 |           64 |
| regnety_008            | 0.76238 | 0.93026 |  54.1286 |           64 |
| resnet50               | 0.76012 | 0.92934 |  89.7976 |           64 |
| densenet169            | 0.75628 | 0.9281  | 127.077  |           64 |
| resnet26               | 0.75394 | 0.92584 |  65.5801 |           64 |
| resnet34               | 0.75096 | 0.92246 |  56.8985 |           64 |
| regnety_006            | 0.75068 | 0.92474 |  55.5611 |           64 |
| regnetx_008            | 0.74788 | 0.92194 |  57.9559 |           64 |
| densenet121            | 0.74472 | 0.91974 | 104.13   |           64 |
| deit_tiny_patch16_224  | 0.7437  | 0.91898 |  66.662  |           64 |
| vgg19_bn               | 0.74216 | 0.91848 | 169.357  |           64 |
| regnety_004            | 0.73766 | 0.91638 |  68.4893 |           64 |
| regnetx_006            | 0.73682 | 0.91568 |  81.4703 |           64 |
| vgg16_bn               | 0.73476 | 0.91536 | 150.317  |           64 |
| vgg19                  | 0.7236  | 0.9085  | 155.851  |           64 |
| regnetx_004            | 0.72298 | 0.90644 |  58.0049 |           64 |
| vgg16                  | 0.71628 | 0.90368 | 135.398  |           64 |
| vgg13_bn               | 0.71618 | 0.9036  | 129.077  |           64 |
| vgg11_bn               | 0.70408 | 0.89724 |  86.9459 |           64 |
| vgg13                  | 0.69984 | 0.89306 | 116.052  |           64 |
| regnety_002            | 0.6998  | 0.89422 |  46.804  |           64 |
| resnet18               | 0.69644 | 0.88982 |  46.2029 |           64 |
| vgg11                  | 0.68872 | 0.88658 |  79.4136 |           64 |
| regnetx_002            | 0.68658 | 0.88244 |  45.9211 |           64 |</p>
<p>Assuming you want to load <code class="docutils literal notranslate"><span class="pre">efficientnet_b1</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models</span> <span class="kn">import</span> <span class="n">EfficientNet</span><span class="p">,</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoTransform</span>

<span class="c1"># load it using AutoModel</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;efficientnet_b1&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># or from its own class</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">EfficientNet</span><span class="o">.</span><span class="n">efficientnet_b1</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># you may also need to get the correct transformation that must be applied on the input</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">AutoTransform</span><span class="o">.</span><span class="n">from_name</span><span class="p">(</span><span class="s1">&#39;efficientnet_b1&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Transform</span><span class="p">(</span>
    <span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">240</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">bicubic</span><span class="p">)</span>
    <span class="n">CenterCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">240</span><span class="p">))</span>
    <span class="n">ToTensor</span><span class="p">()</span>
    <span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.4850</span><span class="p">,</span> <span class="mf">0.4560</span><span class="p">,</span> <span class="mf">0.4060</span><span class="p">]),</span> <span class="n">std</span><span class="o">=</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.2290</span><span class="p">,</span> <span class="mf">0.2240</span><span class="p">,</span> <span class="mf">0.2250</span><span class="p">]))</span>
<span class="p">)</span>
</pre></div>
</div>
<p>In this case, <code class="docutils literal notranslate"><span class="pre">tr</span></code> is</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Compose</span><span class="p">(</span>
    <span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">240</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">BICUBIC</span><span class="p">)</span>
    <span class="n">CenterCrop</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">240</span><span class="p">))</span>
    <span class="n">ToTensor</span><span class="p">()</span>
    <span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="deep-customization">
<h2>Deep Customization<a class="headerlink" href="#deep-customization" title="Permalink to this headline">¬∂</a></h2>
<p>All models are composed by sharable parts:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Block</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Layer</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Head</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Decoder</span></code></p></li>
</ul>
<div class="section" id="block">
<h3>Block<a class="headerlink" href="#block" title="Permalink to this headline">¬∂</a></h3>
<p>Each model has its building block, they are noted by <code class="docutils literal notranslate"><span class="pre">*Block</span></code>. In each block, all the weights are in the <code class="docutils literal notranslate"><span class="pre">.block</span></code> field. This makes it very easy to customize one specific model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models.classification.vgg</span> <span class="kn">import</span> <span class="n">VGGBasicBlock</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.resnet</span> <span class="kn">import</span> <span class="n">ResNetBasicBlock</span><span class="p">,</span> <span class="n">ResNetBottleneckBlock</span><span class="p">,</span> <span class="n">ResNetBasicPreActBlock</span><span class="p">,</span> <span class="n">ResNetBottleneckPreActBlock</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.senet</span> <span class="kn">import</span> <span class="n">SENetBasicBlock</span><span class="p">,</span> <span class="n">SENetBottleneckBlock</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.resnetxt</span> <span class="kn">import</span> <span class="n">ResNetXtBottleNeckBlock</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.densenet</span> <span class="kn">import</span> <span class="n">DenseBottleNeckBlock</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.wide_resnet</span> <span class="kn">import</span> <span class="n">WideResNetBottleNeckBlock</span>
<span class="kn">from</span> <span class="nn">glasses.models.classification.efficientnet</span> <span class="kn">import</span> <span class="n">EfficientNetBasicBlock</span>
</pre></div>
</div>
<p>For example, if we want to add Squeeze and Excitation to the resnet bottleneck block, we can just</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.nn.att</span> <span class="kn">import</span> <span class="n">SpatialSE</span>
<span class="kn">from</span>  <span class="nn">glasses.models.classification.resnet</span> <span class="kn">import</span> <span class="n">ResNetBottleneckBlock</span>

<span class="k">class</span> <span class="nc">SEResNetBottleneckBlock</span><span class="p">(</span><span class="n">ResNetBottleneckBlock</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">squeeze</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># all the weights are in block, we want to apply se after the weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">block</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;se&#39;</span><span class="p">,</span> <span class="n">SpatialSE</span><span class="p">(</span><span class="n">out_features</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">squeeze</span><span class="p">))</span>
        
<span class="n">SEResNetBottleneckBlock</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, we can use the class methods to create the new models following the existing architecture blueprint, for example, to create <code class="docutils literal notranslate"><span class="pre">se_resnet50</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ResNet</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="n">ResNetBottleneckBlock</span><span class="p">)</span>
</pre></div>
</div>
<p>The cool thing is each model has the same api, if I want to create a vgg13 with the <code class="docutils literal notranslate"><span class="pre">ResNetBottleneckBlock</span></code> I can just</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models</span> <span class="kn">import</span> <span class="n">VGG</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VGG</span><span class="o">.</span><span class="n">vgg13</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="n">SEResNetBottleneckBlock</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
<p>Some specific model can require additional parameter to the block, for example <code class="docutils literal notranslate"><span class="pre">MobileNetV2</span></code> also required a <code class="docutils literal notranslate"><span class="pre">expansion</span></code> parameter so our <code class="docutils literal notranslate"><span class="pre">SEResNetBottleneckBlock</span></code> won‚Äôt work.</p>
</div>
<div class="section" id="layer">
<h3>Layer<a class="headerlink" href="#layer" title="Permalink to this headline">¬∂</a></h3>
<p>A <code class="docutils literal notranslate"><span class="pre">Layer</span></code> is a collection of blocks, it is used to stack multiple blocks together following some logic. For example, <code class="docutils literal notranslate"><span class="pre">ResNetLayer</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models.classification.resnet</span> <span class="kn">import</span> <span class="n">ResNetLayer</span>

<span class="n">ResNetLayer</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="encoder">
<h3>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline">¬∂</a></h3>
<p>The encoder is what encoders a vector, so the convolution layers. It has always two very important parameters.</p>
<ul class="simple">
<li><p>widths</p></li>
<li><p>depths</p></li>
</ul>
<p><strong>widths</strong> is the wide at each layer, so how much features there are
<strong>depths</strong> is the depth at each layer, so how many blocks there are</p>
<p>For example, <code class="docutils literal notranslate"><span class="pre">ResNetEncoder</span></code> will creates multiple <code class="docutils literal notranslate"><span class="pre">ResNetLayer</span></code> based on the len of <code class="docutils literal notranslate"><span class="pre">widths</span></code> and <code class="docutils literal notranslate"><span class="pre">depths</span></code>. Let‚Äôs see some example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models.classification.resnet</span> <span class="kn">import</span> <span class="n">ResNetEncoder</span>
<span class="c1"># 3 layers, with 32,64,128 features and 1,2,3 block each</span>
<span class="n">ResNetEncoder</span><span class="p">(</span>
    <span class="n">widths</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">128</span><span class="p">],</span>
    <span class="n">depths</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<p>All encoders are subclass of <code class="docutils literal notranslate"><span class="pre">Encoder</span></code> that allows us to hook on specific stages to get the featuers. All you have to do is first call <code class="docutils literal notranslate"><span class="pre">.features</span></code> to notify the model you want to receive the features, and then pass an input.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">enc</span> <span class="o">=</span> <span class="n">ResNetEncoder</span><span class="p">()</span>
<span class="n">enc</span><span class="o">.</span><span class="n">features</span>
<span class="n">enc</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">([</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">enc</span><span class="o">.</span><span class="n">features</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>Remember</strong> each model has always a <code class="docutils literal notranslate"><span class="pre">.decoder</span></code> field</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models</span> <span class="kn">import</span> <span class="n">ResNet</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ResNet</span><span class="o">.</span><span class="n">resnet18</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">widths</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
<p>The encoder knows the number of output features, you can access them by</p>
<div class="section" id="features">
<h4>Features<a class="headerlink" href="#features" title="Permalink to this headline">¬∂</a></h4>
<p>Each encoder can return a list of features accessable by the <code class="docutils literal notranslate"><span class="pre">.features</span></code> field. You need to call it once before in order to notify the encoder we wish to also store the features</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models.classification.resnet</span> <span class="kn">import</span> <span class="n">ResNetEncoder</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">ResNetEncoder</span><span class="p">()</span>
<span class="n">enc</span><span class="o">.</span><span class="n">features</span> <span class="c1"># call it once</span>
<span class="n">enc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">features</span> <span class="c1"># now we have all the features from each layer (stage)</span>
<span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>
<span class="c1"># torch.Size([1, 64, 112, 112])</span>
<span class="c1"># torch.Size([1, 64, 56, 56])</span>
<span class="c1"># torch.Size([1, 128, 28, 28])</span>
<span class="c1"># torch.Size([1, 256, 14, 14])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="head">
<h3>Head<a class="headerlink" href="#head" title="Permalink to this headline">¬∂</a></h3>
<p>Head is the last part of the model, it usually perform the classification</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models.classification.resnet</span> <span class="kn">import</span> <span class="n">ResNetHead</span>


<span class="n">ResNetHead</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="decoder">
<h3>Decoder<a class="headerlink" href="#decoder" title="Permalink to this headline">¬∂</a></h3>
<p>The decoder takes the last feature from the <code class="docutils literal notranslate"><span class="pre">.encoder</span></code> and decode it. This is usually done in <code class="docutils literal notranslate"><span class="pre">segmentation</span></code> models, such as Unet.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">glasses.models.segmentation.unet</span> <span class="kn">import</span> <span class="n">UNetDecoder</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)</span>
<span class="n">enc</span> <span class="o">=</span> <span class="n">ResNetEncoder</span><span class="p">()</span>
<span class="n">enc</span><span class="o">.</span><span class="n">features</span> <span class="c1"># call it once</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">enc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">enc</span><span class="o">.</span><span class="n">features</span>
<span class="c1"># we need to tell the decoder the first feature size and the size of the lateral features</span>
<span class="n">dec</span> <span class="o">=</span> <span class="n">UNetDecoder</span><span class="p">(</span><span class="n">start_features</span><span class="o">=</span><span class="n">enc</span><span class="o">.</span><span class="n">widths</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">lateral_widths</span><span class="o">=</span><span class="n">enc</span><span class="o">.</span><span class="n">features_widths</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">dec</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">features</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<p><strong>This object oriented structure allows to reuse most of the code across the models</strong></p>
</div>
<div class="section" id="models">
<h3>Models<a class="headerlink" href="#models" title="Permalink to this headline">¬∂</a></h3>
<p>The models so far</p>
<p>üò• = I don‚Äôt have enough GPU RAM</p>
<p>| name                   | Parameters   | Size (MB)   |
|:‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì|:‚Äî‚Äî‚Äî‚Äî-|:‚Äî‚Äî‚Äî‚Äî|
| resnet18               | 11,689,512   | 44.59       |
| resnet26               | 15,995,176   | 61.02       |
| resnet26d              | 16,014,408   | 61.09       |
| resnet34               | 21,797,672   | 83.15       |
| resnet34d              | 21,816,904   | 83.22       |
| resnet50               | 25,557,032   | 97.49       |
| resnet50d              | 25,576,264   | 97.57       |
| resnet101              | 44,549,160   | 169.94      |
| resnet152              | 60,192,808   | 229.62      |
| resnet200              | 64,673,832   | 246.71      |
| se_resnet18            | 11,776,552   | 44.92       |
| se_resnet34            | 21,954,856   | 83.75       |
| se_resnet50            | 28,071,976   | 107.09      |
| se_resnet101           | 49,292,328   | 188.04      |
| se_resnet152           | 66,770,984   | 254.71      |
| cse_resnet18           | 11,778,592   | 44.93       |
| cse_resnet34           | 21,958,868   | 83.77       |
| cse_resnet50           | 28,088,024   | 107.15      |
| cse_resnet101          | 49,326,872   | 188.17      |
| cse_resnet152          | 66,821,848   | 254.91      |
| resnext50_32x4d        | 25,028,904   | 95.48       |
| resnext101_32x8d       | 88,791,336   | 338.71      |
| resnext101_32x16d      | 194,026,792  | 740.15      |
| resnext101_32x32d      | 468,530,472  | 1787.30     |
| resnext101_32x48d      | 828,411,176  | 3160.14     |
| regnetx_002            | 2,684,792    | 10.24       |
| regnetx_004            | 5,157,512    | 19.67       |
| regnetx_006            | 6,196,040    | 23.64       |
| regnetx_008            | 7,259,656    | 27.69       |
| regnetx_016            | 9,190,136    | 35.06       |
| regnetx_032            | 15,296,552   | 58.35       |
| regnety_002            | 3,162,996    | 12.07       |
| regnety_004            | 4,344,144    | 16.57       |
| regnety_006            | 6,055,160    | 23.10       |
| regnety_008            | 6,263,168    | 23.89       |
| regnety_016            | 11,202,430   | 42.73       |
| regnety_032            | 19,436,338   | 74.14       |
| resnest14d             | 10,611,688   | 40.48       |
| resnest26d             | 17,069,448   | 65.11       |
| resnest50d             | 27,483,240   | 104.84      |
| resnest50d_1s4x24d     | 25,677,000   | 97.95       |
| resnest50d_4s2x40d     | 30,417,592   | 116.03      |
| resnest101e            | 48,275,016   | 184.15      |
| resnest200e            | 70,201,544   | 267.80      |
| resnest269e            | 7,551,112    | 28.81       |
| wide_resnet50_2        | 68,883,240   | 262.77      |
| wide_resnet101_2       | 126,886,696  | 484.03      |
| densenet121            | 7,978,856    | 30.44       |
| densenet169            | 14,149,480   | 53.98       |
| densenet201            | 20,013,928   | 76.35       |
| densenet161            | 28,681,000   | 109.41      |
| fishnet99              | 16,630,312   | 63.44       |
| fishnet150             | 24,960,808   | 95.22       |
| vgg11                  | 132,863,336  | 506.83      |
| vgg13                  | 133,047,848  | 507.54      |
| vgg16                  | 138,357,544  | 527.79      |
| vgg19                  | 143,667,240  | 548.05      |
| vgg11_bn               | 132,868,840  | 506.85      |
| vgg13_bn               | 133,053,736  | 507.56      |
| vgg16_bn               | 138,365,992  | 527.82      |
| vgg19_bn               | 143,678,248  | 548.09      |
| efficientnet_b0        | 5,288,548    | 20.17       |
| efficientnet_b1        | 7,794,184    | 29.73       |
| efficientnet_b2        | 9,109,994    | 34.75       |
| efficientnet_b3        | 12,233,232   | 46.67       |
| efficientnet_b4        | 19,341,616   | 73.78       |
| efficientnet_b5        | 30,389,784   | 115.93      |
| efficientnet_b6        | 43,040,704   | 164.19      |
| efficientnet_b7        | 66,347,960   | 253.10      |
| efficientnet_b8        | üò•           | üò•          |
| efficientnet_l2        | üò•           | üò•          |
| efficientnet_lite0     | 4,652,008    | 17.75       |
| efficientnet_lite1     | 5,416,680    | 20.66       |
| efficientnet_lite2     | 6,092,072    | 23.24       |
| efficientnet_lite3     | 8,197,096    | 31.27       |
| efficientnet_lite4     | 13,006,568   | 49.62       |
| vit_small_patch16_224  | 48,602,344   | 185.40      |
| vit_base_patch16_224   | 86,415,592   | 329.65      |
| vit_base_patch16_384   | 86,415,592   | 329.65      |
| vit_base_patch32_384   | 88,185,064   | 336.40      |
| vit_huge_patch16_224   | 631,823,080  | 2410.21     |
| vit_huge_patch32_384   | 634,772,200  | 2421.46     |
| vit_large_patch16_224  | 304,123,880  | 1160.14     |
| vit_large_patch16_384  | 304,123,880  | 1160.14     |
| vit_large_patch32_384  | 306,483,176  | 1169.14     |
| deit_tiny_patch16_224  | 5,872,400    | 22.40       |
| deit_small_patch16_224 | 22,359,632   | 85.30       |
| deit_base_patch16_224  | 87,184,592   | 332.58      |
| mobilenetv2            | 3,504,872    | 13.37       |
| unet                   | 23,202,530   | 88.51       |
| deit_base_patch16_384  | 87,184,592   | 332.58      |</p>
</div>
</div>
<div class="section" id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="Permalink to this headline">¬∂</a></h2>
<p>Most of the weights were trained by other people and adapted to glasses. It is worth cite</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/rwightman/pytorch-image-models">pytorch-image-models</a></p></li>
<li><p><a class="reference external" href="hhttps://github.com/pytorch/vision">torchvision</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Francesco Saverio Zuppichini &amp; Francesco Cicala.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>