{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "URL = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvertedResidualBlock(\n",
       "  (block): Sequential(\n",
       "    (exp): ConvBnAct(\n",
       "      (conv): Conv2dPad(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU6()\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): DeepthWiseConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "      (1): Conv2dPad(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.mobilenet import MobileNetBasicBlock,MobileNetEncoder\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder\n",
    "\n",
    "\n",
    "MobileNetBasicBlock(16, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Conv2dPad-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "  DeepthWiseConv2d-4         [-1, 32, 112, 112]             320\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "         Conv2dPad-7         [-1, 16, 112, 112]             528\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "InvertedResidualBlock-9         [-1, 16, 112, 112]               0\n",
      "   MobileNetLayer-10         [-1, 16, 112, 112]               0\n",
      "        Conv2dPad-11         [-1, 96, 112, 112]           1,632\n",
      "      BatchNorm2d-12         [-1, 96, 112, 112]             192\n",
      "            ReLU6-13         [-1, 96, 112, 112]               0\n",
      " DeepthWiseConv2d-14           [-1, 96, 56, 56]             960\n",
      "      BatchNorm2d-15           [-1, 96, 56, 56]             192\n",
      "            ReLU6-16           [-1, 96, 56, 56]               0\n",
      "        Conv2dPad-17           [-1, 24, 56, 56]           2,328\n",
      "      BatchNorm2d-18           [-1, 24, 56, 56]              48\n",
      "InvertedResidualBlock-19           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-20          [-1, 144, 56, 56]           3,600\n",
      "      BatchNorm2d-21          [-1, 144, 56, 56]             288\n",
      "            ReLU6-22          [-1, 144, 56, 56]               0\n",
      " DeepthWiseConv2d-23          [-1, 144, 56, 56]           1,440\n",
      "      BatchNorm2d-24          [-1, 144, 56, 56]             288\n",
      "            ReLU6-25          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-26           [-1, 24, 56, 56]           3,480\n",
      "      BatchNorm2d-27           [-1, 24, 56, 56]              48\n",
      "         Residual-28           [-1, 24, 56, 56]               0\n",
      "InvertedResidualBlock-29           [-1, 24, 56, 56]               0\n",
      "   MobileNetLayer-30           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-31          [-1, 144, 56, 56]           3,600\n",
      "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
      "            ReLU6-33          [-1, 144, 56, 56]               0\n",
      " DeepthWiseConv2d-34          [-1, 144, 28, 28]           1,440\n",
      "      BatchNorm2d-35          [-1, 144, 28, 28]             288\n",
      "            ReLU6-36          [-1, 144, 28, 28]               0\n",
      "        Conv2dPad-37           [-1, 32, 28, 28]           4,640\n",
      "      BatchNorm2d-38           [-1, 32, 28, 28]              64\n",
      "InvertedResidualBlock-39           [-1, 32, 28, 28]               0\n",
      "        Conv2dPad-40          [-1, 192, 28, 28]           6,336\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      " DeepthWiseConv2d-43          [-1, 192, 28, 28]           1,920\n",
      "      BatchNorm2d-44          [-1, 192, 28, 28]             384\n",
      "            ReLU6-45          [-1, 192, 28, 28]               0\n",
      "        Conv2dPad-46           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-47           [-1, 32, 28, 28]              64\n",
      "         Residual-48           [-1, 32, 28, 28]               0\n",
      "InvertedResidualBlock-49           [-1, 32, 28, 28]               0\n",
      "        Conv2dPad-50          [-1, 192, 28, 28]           6,336\n",
      "      BatchNorm2d-51          [-1, 192, 28, 28]             384\n",
      "            ReLU6-52          [-1, 192, 28, 28]               0\n",
      " DeepthWiseConv2d-53          [-1, 192, 28, 28]           1,920\n",
      "      BatchNorm2d-54          [-1, 192, 28, 28]             384\n",
      "            ReLU6-55          [-1, 192, 28, 28]               0\n",
      "        Conv2dPad-56           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-57           [-1, 32, 28, 28]              64\n",
      "         Residual-58           [-1, 32, 28, 28]               0\n",
      "InvertedResidualBlock-59           [-1, 32, 28, 28]               0\n",
      "   MobileNetLayer-60           [-1, 32, 28, 28]               0\n",
      "        Conv2dPad-61          [-1, 192, 28, 28]           6,336\n",
      "      BatchNorm2d-62          [-1, 192, 28, 28]             384\n",
      "            ReLU6-63          [-1, 192, 28, 28]               0\n",
      " DeepthWiseConv2d-64          [-1, 192, 14, 14]           1,920\n",
      "      BatchNorm2d-65          [-1, 192, 14, 14]             384\n",
      "            ReLU6-66          [-1, 192, 14, 14]               0\n",
      "        Conv2dPad-67           [-1, 64, 14, 14]          12,352\n",
      "      BatchNorm2d-68           [-1, 64, 14, 14]             128\n",
      "InvertedResidualBlock-69           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-70          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-71          [-1, 384, 14, 14]             768\n",
      "            ReLU6-72          [-1, 384, 14, 14]               0\n",
      " DeepthWiseConv2d-73          [-1, 384, 14, 14]           3,840\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "        Conv2dPad-76           [-1, 64, 14, 14]          24,640\n",
      "      BatchNorm2d-77           [-1, 64, 14, 14]             128\n",
      "         Residual-78           [-1, 64, 14, 14]               0\n",
      "InvertedResidualBlock-79           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-80          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-81          [-1, 384, 14, 14]             768\n",
      "            ReLU6-82          [-1, 384, 14, 14]               0\n",
      " DeepthWiseConv2d-83          [-1, 384, 14, 14]           3,840\n",
      "      BatchNorm2d-84          [-1, 384, 14, 14]             768\n",
      "            ReLU6-85          [-1, 384, 14, 14]               0\n",
      "        Conv2dPad-86           [-1, 64, 14, 14]          24,640\n",
      "      BatchNorm2d-87           [-1, 64, 14, 14]             128\n",
      "         Residual-88           [-1, 64, 14, 14]               0\n",
      "InvertedResidualBlock-89           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-90          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-91          [-1, 384, 14, 14]             768\n",
      "            ReLU6-92          [-1, 384, 14, 14]               0\n",
      " DeepthWiseConv2d-93          [-1, 384, 14, 14]           3,840\n",
      "      BatchNorm2d-94          [-1, 384, 14, 14]             768\n",
      "            ReLU6-95          [-1, 384, 14, 14]               0\n",
      "        Conv2dPad-96           [-1, 64, 14, 14]          24,640\n",
      "      BatchNorm2d-97           [-1, 64, 14, 14]             128\n",
      "         Residual-98           [-1, 64, 14, 14]               0\n",
      "InvertedResidualBlock-99           [-1, 64, 14, 14]               0\n",
      "  MobileNetLayer-100           [-1, 64, 14, 14]               0\n",
      "       Conv2dPad-101          [-1, 384, 14, 14]          24,960\n",
      "     BatchNorm2d-102          [-1, 384, 14, 14]             768\n",
      "           ReLU6-103          [-1, 384, 14, 14]               0\n",
      "DeepthWiseConv2d-104          [-1, 384, 14, 14]           3,840\n",
      "     BatchNorm2d-105          [-1, 384, 14, 14]             768\n",
      "           ReLU6-106          [-1, 384, 14, 14]               0\n",
      "       Conv2dPad-107           [-1, 96, 14, 14]          36,960\n",
      "     BatchNorm2d-108           [-1, 96, 14, 14]             192\n",
      "InvertedResidualBlock-109           [-1, 96, 14, 14]               0\n",
      "       Conv2dPad-110          [-1, 576, 14, 14]          55,872\n",
      "     BatchNorm2d-111          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-112          [-1, 576, 14, 14]               0\n",
      "DeepthWiseConv2d-113          [-1, 576, 14, 14]           5,760\n",
      "     BatchNorm2d-114          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-115          [-1, 576, 14, 14]               0\n",
      "       Conv2dPad-116           [-1, 96, 14, 14]          55,392\n",
      "     BatchNorm2d-117           [-1, 96, 14, 14]             192\n",
      "        Residual-118           [-1, 96, 14, 14]               0\n",
      "InvertedResidualBlock-119           [-1, 96, 14, 14]               0\n",
      "       Conv2dPad-120          [-1, 576, 14, 14]          55,872\n",
      "     BatchNorm2d-121          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-122          [-1, 576, 14, 14]               0\n",
      "DeepthWiseConv2d-123          [-1, 576, 14, 14]           5,760\n",
      "     BatchNorm2d-124          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-125          [-1, 576, 14, 14]               0\n",
      "       Conv2dPad-126           [-1, 96, 14, 14]          55,392\n",
      "     BatchNorm2d-127           [-1, 96, 14, 14]             192\n",
      "        Residual-128           [-1, 96, 14, 14]               0\n",
      "InvertedResidualBlock-129           [-1, 96, 14, 14]               0\n",
      "  MobileNetLayer-130           [-1, 96, 14, 14]               0\n",
      "       Conv2dPad-131          [-1, 576, 14, 14]          55,872\n",
      "     BatchNorm2d-132          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-133          [-1, 576, 14, 14]               0\n",
      "DeepthWiseConv2d-134            [-1, 576, 7, 7]           5,760\n",
      "     BatchNorm2d-135            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-136            [-1, 576, 7, 7]               0\n",
      "       Conv2dPad-137            [-1, 160, 7, 7]          92,320\n",
      "     BatchNorm2d-138            [-1, 160, 7, 7]             320\n",
      "InvertedResidualBlock-139            [-1, 160, 7, 7]               0\n",
      "       Conv2dPad-140            [-1, 960, 7, 7]         154,560\n",
      "     BatchNorm2d-141            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-142            [-1, 960, 7, 7]               0\n",
      "DeepthWiseConv2d-143            [-1, 960, 7, 7]           9,600\n",
      "     BatchNorm2d-144            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-145            [-1, 960, 7, 7]               0\n",
      "       Conv2dPad-146            [-1, 160, 7, 7]         153,760\n",
      "     BatchNorm2d-147            [-1, 160, 7, 7]             320\n",
      "        Residual-148            [-1, 160, 7, 7]               0\n",
      "InvertedResidualBlock-149            [-1, 160, 7, 7]               0\n",
      "       Conv2dPad-150            [-1, 960, 7, 7]         154,560\n",
      "     BatchNorm2d-151            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-152            [-1, 960, 7, 7]               0\n",
      "DeepthWiseConv2d-153            [-1, 960, 7, 7]           9,600\n",
      "     BatchNorm2d-154            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-155            [-1, 960, 7, 7]               0\n",
      "       Conv2dPad-156            [-1, 160, 7, 7]         153,760\n",
      "     BatchNorm2d-157            [-1, 160, 7, 7]             320\n",
      "        Residual-158            [-1, 160, 7, 7]               0\n",
      "InvertedResidualBlock-159            [-1, 160, 7, 7]               0\n",
      "  MobileNetLayer-160            [-1, 160, 7, 7]               0\n",
      "       Conv2dPad-161            [-1, 960, 7, 7]         154,560\n",
      "     BatchNorm2d-162            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-163            [-1, 960, 7, 7]               0\n",
      "DeepthWiseConv2d-164            [-1, 960, 7, 7]           9,600\n",
      "     BatchNorm2d-165            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-166            [-1, 960, 7, 7]               0\n",
      "       Conv2dPad-167            [-1, 320, 7, 7]         307,520\n",
      "     BatchNorm2d-168            [-1, 320, 7, 7]             640\n",
      "InvertedResidualBlock-169            [-1, 320, 7, 7]               0\n",
      "  MobileNetLayer-170            [-1, 320, 7, 7]               0\n",
      "       Conv2dPad-171           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-172           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-173           [-1, 1280, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 2,239,648\n",
      "Trainable params: 2,239,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 157.22\n",
      "Params size (MB): 8.54\n",
      "Estimated Total Size (MB): 166.33\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9627cee81353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/torcheyes/glasses/nn/models/classification/mobilenet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 345\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    346\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "encoder = MobileNetEncoder(\n",
    "#               depths=[1, 2, 1, 1, 1, 1, 1],\n",
    "              block=MobileNetBasicBlock)\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "model = encoder.cuda()\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "encoder(x).shape\n",
    "# encoder\n",
    "\n",
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepthWiseConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, groups=out_channels, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 166.81\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model = mobilenet_v2()\n",
    "\n",
    "summary(model.cuda(), (3, 224, 224))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Add Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "\n",
    "    def __init__(self, block: nn.Module,\n",
    "                 res_func: Callable[[Tensor], Tensor] = None,\n",
    "                 shortcut: nn.Module = None, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "        self.res_func = res_func\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        if self.res_func is not None:\n",
    "            x = self.res_func(x, res)\n",
    "        return x\n",
    "\n",
    "\n",
    "def add(x: Tensor, res: Tensor) -> Tensor:\n",
    "    return x.add_(res)\n",
    "\n",
    "\n",
    "ResidualAdd = partial(Residual, res_func=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.3 ms  6.57 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = ResidualAdd(nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                \n",
    "            ))\n",
    "\n",
    "x = torch.rand(1,64, 48, 48)\n",
    "\n",
    "for _ in range(10):\n",
    "    m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, block: nn.Module,\n",
    "                 shortcut: nn.Module = None, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        x += res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.7 ms  2.5 ms per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = ResidualAdd(nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                \n",
    "            ))\n",
    "\n",
    "x = torch.rand(1,64, 48, 48)\n",
    "\n",
    "for _ in range(10):\n",
    "    m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (gate): Sequential(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ResnetDecoder(\n",
       "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.utils.PretrainedWeightsProvider import PretrainedWeightsProvider\n",
    "\n",
    "# test if the weights are correct, only for resnet18 \n",
    "PretrainedWeightsProvider()['resnet18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-977f1222c54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNetBasicBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, activation, downsampling, conv)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 }\n\u001b[1;32m     68\u001b[0m             )), shortcut=ResNetShorcut(\n\u001b[0;32m---> 69\u001b[0;31m             in_features, out_features * self.expansion, downsampling) if in_features != out_features * self.expansion else None)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/blocks/residuals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, shortcut, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     def __init__(self, block: nn.Module,\n\u001b[1;32m     62\u001b[0m                  shortcut: nn.Module = None, *args, **kwargs):\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetBasicBlock\n",
    "\n",
    "\n",
    "ResNetBasicBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of glasses.nn.models.classification.resnet failed: Traceback (most recent call last):\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: forward() requires a code object with 1 free vars, not 0\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8543bc12316a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(cls, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFrancescoSaverioZuppichini\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mglasses\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdevelop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0m_static\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mResNet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mresnet18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, n_classes, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0min_channels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mRGB\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mGray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, blocks_sizes, depths, activation, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         self.blocks = nn.ModuleList([\n\u001b[1;32m    227\u001b[0m             ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=depths[0], activation=activation,\n\u001b[0;32m--> 228\u001b[0;31m                         block=block,  *args, **kwargs),\n\u001b[0m\u001b[1;32m    229\u001b[0m             *[ResNetLayer(in_channels * block.expansion,\n\u001b[1;32m    230\u001b[0m                           \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, block, n, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         self.block = nn.Sequential(\n\u001b[1;32m    190\u001b[0m             block(in_channels, out_channels, *args,\n\u001b[0;32m--> 191\u001b[0;31m                   downsampling=downsampling,  **kwargs),\n\u001b[0m\u001b[1;32m    192\u001b[0m             *[block(out_channels * block.expansion,\n\u001b[1;32m    193\u001b[0m                     out_channels, *args, **kwargs) for _ in range(n - 1)]\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, activation, downsampling, conv)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mactivation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLUInPlace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification import ResNet\n",
    "\n",
    "\n",
    "ResNet.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n",
      "  (block): Residual(\n",
      "    (block): Sequential(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (shortcut): ResNetShorcut(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (act): ReLU(inplace=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3507, 0.0000, 0.2612,  ..., 0.0000, 0.0000, 1.0867],\n",
       "          [0.0000, 0.9422, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.2224, 0.2569],\n",
       "          ...,\n",
       "          [0.4459, 0.3775, 3.1123,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 1.2234,  ..., 1.2519, 0.0000, 0.7491],\n",
       "          [0.0000, 0.0000, 0.3720,  ..., 0.0000, 0.8578, 0.0000]],\n",
       "\n",
       "         [[0.4809, 0.6557, 2.3329,  ..., 0.0000, 0.0000, 0.7809],\n",
       "          [0.0000, 0.8320, 0.0000,  ..., 0.1316, 1.9552, 0.2474],\n",
       "          [0.0000, 0.7629, 0.2113,  ..., 0.0000, 0.0000, 0.3037],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 2.3773,  ..., 0.0000, 0.0000, 0.6268],\n",
       "          [0.0000, 0.0000, 0.8727,  ..., 1.7412, 0.0000, 0.2877],\n",
       "          [0.0000, 2.0063, 3.6411,  ..., 2.3751, 0.0000, 1.7510]],\n",
       "\n",
       "         [[0.6819, 0.0000, 0.6205,  ..., 0.0000, 0.9400, 1.5356],\n",
       "          [0.0000, 1.3500, 1.0352,  ..., 0.8879, 2.3182, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6350, 1.6081, 0.7301],\n",
       "          ...,\n",
       "          [0.4442, 0.0000, 2.1246,  ..., 0.0966, 0.7882, 1.5920],\n",
       "          [1.4873, 0.0000, 0.2683,  ..., 0.0000, 1.6488, 0.2661],\n",
       "          [0.3257, 0.2221, 0.7868,  ..., 0.2541, 1.7204, 0.7284]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.7185, 1.8092, 0.0000,  ..., 0.4413, 0.0000, 0.3170],\n",
       "          [0.4104, 0.8848, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 2.2277, 0.5118,  ..., 0.3384, 2.4265, 0.7051],\n",
       "          ...,\n",
       "          [1.0232, 0.0000, 0.0000,  ..., 0.3878, 1.3228, 0.0000],\n",
       "          [0.3232, 3.1274, 2.9078,  ..., 1.2931, 0.1088, 0.0000],\n",
       "          [0.0000, 0.0000, 2.6110,  ..., 0.0000, 0.2240, 0.0000]],\n",
       "\n",
       "         [[1.8617, 0.0656, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.1593, 0.0000,  ..., 2.3392, 0.9732, 0.0000],\n",
       "          [2.5130, 0.0000, 0.0000,  ..., 0.0000, 1.3642, 0.0000],\n",
       "          ...,\n",
       "          [3.9152, 0.0000, 0.9247,  ..., 0.0000, 0.1743, 1.4785],\n",
       "          [2.7101, 0.0000, 0.0000,  ..., 0.0000, 0.6275, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9267, 0.0572]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.8738, 0.0000],\n",
       "          [0.0000, 0.7810, 1.7678,  ..., 1.5005, 0.0000, 0.8167],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.3869, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 1.4338,  ..., 0.9423, 0.0000, 0.0000],\n",
       "          [0.0000, 1.6954, 2.1104,  ..., 1.6115, 4.0714, 0.0000],\n",
       "          [0.4486, 0.0000, 0.2714,  ..., 2.8716, 0.9764, 0.0000]]]],\n",
       "       grad_fn=<ReluBackward1>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetBasicBlock\n",
    "\n",
    "x = torch.rand(1, 32, 48, 48)\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "print(block)\n",
    "block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
